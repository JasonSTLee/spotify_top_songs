{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyOAuth\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "from spotipy import Spotify\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "import psycopg2.extras\n",
    "import os\n",
    "import sys\n",
    "import config\n",
    "import json\n",
    "import pprint\n",
    "import glob\n",
    "from config.conf import conf\n",
    "from utils.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Liked Songs Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_d/ck_82j6x2vx7b1w6jlm_5cjr0000gn/T/ipykernel_5383/1928061993.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  like_songs_clean.drop('track', axis = 1, inplace = True)\n",
      "/var/folders/_d/ck_82j6x2vx7b1w6jlm_5cjr0000gn/T/ipykernel_5383/1928061993.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  like_songs_clean['added_at'] = like_songs_clean['added_at'].str.replace('[a-zA-Z]', ' ', regex = True).str.strip()\n",
      "/var/folders/_d/ck_82j6x2vx7b1w6jlm_5cjr0000gn/T/ipykernel_5383/1928061993.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  like_songs_clean['artists'] = like_songs_clean['artists'].apply(sorted)\n"
     ]
    }
   ],
   "source": [
    "scope_library = 'user-library-read'\n",
    "\n",
    "sp_auth = SpotifyOAuth(\n",
    "    client_id = conf['client_id'],\n",
    "    client_secret = conf['client_secret'],\n",
    "    redirect_uri = conf['redirect_url'], \n",
    "    scope = scope_library\n",
    ")\n",
    "\n",
    "sp = Spotify(auth_manager = sp_auth)\n",
    "\n",
    "# Initialize variables for the While Loop\n",
    "all_like_songs = []\n",
    "offset = 0\n",
    "limit = 50\n",
    "\n",
    "# Loop over my playlist to retrieve all tracks\n",
    "while True:\n",
    "    results = sp.current_user_saved_tracks(limit = limit, offset = offset)\n",
    "    \n",
    "    for item in results['items']:\n",
    "        track = item['track']\n",
    "        \n",
    "        track_info = {\n",
    "            'added_at': item['added_at'],\n",
    "            'artists': [artist['name'] for artist in track['artists']],\n",
    "            'name': track['name'],\n",
    "            'album': track['album']['name'],\n",
    "            'duration': track['duration_ms']\n",
    "        }\n",
    "        all_like_songs.append(track_info)\n",
    "        \n",
    "    # Adding results to the list\n",
    "    all_like_songs.extend(results['items'])\n",
    "    \n",
    "    # If fewer than limit 50, then break while loop because loop has reached the end\n",
    "    if len(results['items']) < limit:\n",
    "        break\n",
    "    \n",
    "    # Increment the offset to get next set of tracks after each loop\n",
    "    offset += limit\n",
    "\n",
    "like_songs_df = pd.DataFrame(all_like_songs)\n",
    "like_songs_clean = like_songs_df.query(' name.notnull() ')\n",
    "like_songs_clean.drop('track', axis = 1, inplace = True)\n",
    "like_songs_clean['added_at'] = like_songs_clean['added_at'].str.replace('[a-zA-Z]', ' ', regex = True).str.strip()\n",
    "like_songs_clean['artists'] = like_songs_clean['artists'].apply(sorted)\n",
    "\n",
    "# Initializing columns to create table\n",
    "like_songs_col = like_songs_clean.columns.tolist()\n",
    "like_songs_types = ['TIMESTAMP', 'TEXT[]', 'VARCHAR(200)', 'VARCHAR(200)', 'NUMERIC']\n",
    "\n",
    "create_table(like_songs_clean, 'liked_songs', like_songs_col, like_songs_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming History Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_list = []\n",
    "\n",
    "for jsons in glob.glob('Spotify Account Data/StreamingHistory_music*.json'):\n",
    "    with open(jsons, 'r') as file:\n",
    "        data  = json.load(file)\n",
    "        \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Creating TIMESTAMP columns\n",
    "    df['endTime_full'] = pd.to_datetime(df['endTime'], format = '%Y-%m-%d %H:%M')\n",
    "    df['startTime'] = df['endTime_full'] - pd.to_timedelta(df['msPlayed'], unit = 'ms')\n",
    "    \n",
    "    # Creating ArtistName ARRAY column\n",
    "    df['artistNameArray'] = df['trackName'].str.extract(r'\\(feat\\.\\s*(.*?)\\)')\n",
    "    df['artistName'] = df[['artistName', 'artistNameArray']].values.tolist()\n",
    "    \n",
    "    def remove_nan(col):\n",
    "        return [x for x in col if not pd.isna(x)]\n",
    "    \n",
    "    df['artistName'] = df['artistName'].apply(remove_nan)\n",
    "    df['artistName'] = df['artistName'].apply(sorted)\n",
    "    \n",
    "    df = df[['trackName', 'artistName', 'endTime', 'startTime', 'msPlayed']]\n",
    "    \n",
    "    json_list.append(df)\n",
    "\n",
    "streaming_hist_df = pd.concat(json_list)\n",
    "\n",
    "streaming_hist_col = streaming_hist_df.columns.tolist()\n",
    "streaming_hist_types = ['VARCHAR(200)', 'TEXT[]', 'TIMESTAMP', 'TIMESTAMP', 'NUMERIC']\n",
    "\n",
    "create_table(streaming_hist_df, 'streaming_hist', streaming_hist_col, streaming_hist_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search Query Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Spotify Account Data/SearchQueries.json', 'r') as file:\n",
    "        data  = json.load(file)\n",
    "\n",
    "search_df = pd.DataFrame(data)[['searchTime', 'searchQuery']]\n",
    "search_df['searchTime'] = search_df['searchTime'].str.rstrip(to_strip = 'Z[UTC]').str.replace('T', ' ')\n",
    "\n",
    "\n",
    "search_df_col = search_df.columns.tolist()\n",
    "search_df_types = ['TIMESTAMP', 'VARCHAR(200)']\n",
    "\n",
    "create_table(search_df, 'search_query', search_df_col, search_df_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_table(table_name):\n",
    "#     try:\n",
    "#         conn = psycopg2.connect(host = conf.host, dbname = conf.dbname, user = conf.user, password = conf.password, port = conf.port)\n",
    "#         cur = conn.cursor()\n",
    "\n",
    "#         cur.execute(\"\"\" DROP TABLE IF EXISTS liked_songs \"\"\")\n",
    "        \n",
    "#         cur.execute(\"\"\"\n",
    "#                     CREATE TABLE IF NOT EXISTS liked_songs(\n",
    "#                                             added_date VARCHAR(200),\n",
    "#                                             artists TEXT[],\n",
    "#                                             song_name VARCHAR(200)\n",
    "#                     )\n",
    "#                     \"\"\")\n",
    "        \n",
    "#         insert_query = \"\"\"\n",
    "#             INSERT INTO liked_songs (added_date, artists, song_name)\n",
    "#             VALUES (%s, %s, %s)\n",
    "#         \"\"\"\n",
    "        \n",
    "#         for _, row in df_clean.iterrows():\n",
    "#             cur.execute(insert_query, (row['added_at'], row['artists'], row['name']))\n",
    "\n",
    "\n",
    "#         conn.commit()\n",
    "\n",
    "#         cur.close()\n",
    "#         conn.close()\n",
    "#     except Exception as error:\n",
    "#         print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_table(df, table_name, column_list, column_schema_list):\n",
    "#     \"\"\"\n",
    "    \n",
    "#     Creating a PostgreSQL table from Pandas DataFrame\n",
    "#     Parameters:\n",
    "#         DF: Pandas DataFrame (clean Dataframe beforehand so the input is the intended dtype)\n",
    "#         Table_name: Name shown in Postgres\n",
    "#         Column_list: List of column names in DataFrame\n",
    "#         Column_schema_list: List of dtypes from DataFrame that must match the order of column_list\n",
    "        \n",
    "#     \"\"\"\n",
    "    \n",
    "#     try:\n",
    "#         # Connect to the database\n",
    "#         conn = psycopg2.connect(\n",
    "#             host=conf.host, \n",
    "#             dbname=conf.dbname, \n",
    "#             user=conf.user, \n",
    "#             password=conf.password, \n",
    "#             port=conf.port\n",
    "#         )\n",
    "#         cur = conn.cursor()\n",
    "\n",
    "#         # Drop table if it exists\n",
    "#         cur.execute(f\"\"\" \n",
    "#                     DROP TABLE IF EXISTS {table_name}\n",
    "#                     \"\"\")\n",
    "\n",
    "#         # Construct CREATE TABLE dynamically\n",
    "#         columns_with_types = ', '.join([f'{col} {dtype}' for col, dtype in zip(column_list, column_schema_list)])\n",
    "#         create_table_query = f\"\"\"\n",
    "#                     CREATE TABLE IF NOT EXISTS {table_name} ({columns_with_types})\n",
    "#                     \"\"\"\n",
    "\n",
    "#         # Execute CREATE TABLE \n",
    "#         cur.execute(create_table_query)\n",
    "\n",
    "#         # Construct INSERT query dynamically\n",
    "#         placeholders = \", \".join([\"%s\"] * len(column_list))\n",
    "#         insert_query = f\"\"\"\n",
    "#                     INSERT INTO {table_name} ({', '.join(column_list)}) VALUES ({placeholders})\n",
    "#                      \"\"\"\n",
    "\n",
    "#         # Insert rows from dataframe\n",
    "#         for _, row in df.iterrows():\n",
    "#             cur.execute(insert_query, tuple(row[col] for col in column_list))\n",
    "\n",
    "\n",
    "#         conn.commit()\n",
    "#         cur.close()\n",
    "#         conn.close()\n",
    "#     except Exception as error:\n",
    "#         print(error)\n",
    "\n",
    "\n",
    "# columns = ['added_at', 'artists', 'name']\n",
    "# column_types = ['VARCHAR(200)', 'TEXT[]', 'VARCHAR(200)']\n",
    "\n",
    "# create_table(df_clean, 'liked_songs', columns, column_types)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
